# from langchain.vectorstores import FAISS
# from langchain.embeddings.openai import OpenAIEmbeddings
# from langchain.prompts import PromptTemplate
# from langchain.document_loaders import TextLoader
# from langchain.text_splitter import CharacterTextSplitter
# from langchain.chat_models import AzureChatOpenAI
# from langchain.chains import RetrievalQA

# import os

# os.environ["OPENAI_API_TYPE"] = "azure"
# os.environ["OPENAI_API_VERSION"] = "2023-07-01-preview"
# os.environ["OPENAI_API_BASE"] = ""
# os.environ["OPENAI_API_KEY"] = "sk-"

# embedding_model = OpenAIEmbeddings(chunk_size=10)

# OCR_Content = TextLoader('OCR_Result.txt').load()
# text_splitter = CharacterTextSplitter(chunk_overlap=100)
# content = text_splitter.split_documents(OCR_Content)

# faiss_db = FAISS.from_documents(content, embedding_model)
# retriever = faiss_db.as_retriever(search_type="similarity", search_kwargs={"k": 4})

# llm = AzureChatOpenAI(
#     temperature=0,
#     deployment_name="gpt-4",
# )

# prompt_template = """

# Your objective is to analyze the provided data in JSON format.

# JSON Data:
# {context}
    
# User questions: 
# {question}

# Reply to the user in JSON format, incorporating the key-value pairs:

# """
# QA_PROMPT = PromptTemplate(
#     template=prompt_template, input_variables=['context', 'question']
# )

# qa_chain = RetrievalQA.from_chain_type(
#     llm=llm, 
#     retriever=retriever, 
#     chain_type_kwargs={"prompt": QA_PROMPT},
#     verbose=True
# )

# question = """
# Extract the detailed line items in table format and Total Amount
# """

# result = qa_chain({"query": question})
# print(result["result"])
