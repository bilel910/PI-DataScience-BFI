{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr # main OCR dependencies\n",
    "from matplotlib import pyplot as plt # plot images\n",
    "import cv2 #opencv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/03/03 18:40:17] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\kortb/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\kortb/.paddleocr/whl\\\\rec\\\\latin\\\\latin_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\kortb\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\latin_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\kortb/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='french', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "ocr_model = PaddleOCR(use_gpu=False,lang='french')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Users/kortb/Desktop/BFI/myenv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/03/03 18:40:21] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/03/03 18:40:21] ppocr DEBUG: dt_boxes num : 49, elapsed : 0.11252665519714355\n",
      "[2024/03/03 18:40:22] ppocr DEBUG: rec_res num  : 49, elapsed : 1.087775468826294\n"
     ]
    }
   ],
   "source": [
    "img_path = '3.png'\n",
    "result = ocr_model.ocr(img_path, cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/03/03 18:40:24] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/03/03 18:40:24] ppocr DEBUG: dt_boxes num : 49, elapsed : 0.08952474594116211\n",
      "[2024/03/03 18:40:25] ppocr DEBUG: rec_res num  : 49, elapsed : 0.9762678146362305\n"
     ]
    }
   ],
   "source": [
    "result = ocr_model.ocr(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[[19.0, 3.0], [52.0, 3.0], [52.0, 19.0], [19.0, 19.0]],\n",
       "   ('PASSIE', 0.9941186308860779)],\n",
       "  [[[1.0, 22.0], [194.0, 22.0], [194.0, 35.0], [1.0, 35.0]],\n",
       "   ('1 - Banque centrale et Centre de cheques postaux', 0.9737885594367981)],\n",
       "  [[[369.0, 23.0], [378.0, 23.0], [378.0, 36.0], [369.0, 36.0]],\n",
       "   (' 0', 0.7499680519104004)],\n",
       "  [[[2.0, 41.0], [242.0, 41.0], [242.0, 55.0], [2.0, 55.0]],\n",
       "   ('2 - Dépöts et avoirs des etablissements bancaires et financiers',\n",
       "    0.9691433906555176)],\n",
       "  [[[294.0, 42.0], [311.0, 42.0], [311.0, 57.0], [294.0, 57.0]],\n",
       "   ('4.7', 0.998425304889679)],\n",
       "  [[[348.0, 42.0], [378.0, 42.0], [378.0, 57.0], [348.0, 57.0]],\n",
       "   ('31 750', 0.9897408485412598)],\n",
       "  [[[426.0, 42.0], [456.0, 42.0], [456.0, 57.0], [426.0, 57.0]],\n",
       "   ('57 533', 0.9681021571159363)],\n",
       "  [[[2.0, 71.0], [133.0, 71.0], [133.0, 85.0], [2.0, 85.0]],\n",
       "   ('3 - Depots et avoirs de la clientele', 0.9898083806037903)],\n",
       "  [[[294.0, 70.0], [312.0, 70.0], [312.0, 88.0], [294.0, 88.0]],\n",
       "   ('4.8', 0.9892773032188416)],\n",
       "  [[[345.0, 71.0], [378.0, 71.0], [378.0, 86.0], [345.0, 86.0]],\n",
       "   ('103 215', 0.9980849027633667)],\n",
       "  [[[426.0, 71.0], [456.0, 71.0], [456.0, 87.0], [426.0, 87.0]],\n",
       "   ('82 517', 0.981601893901825)],\n",
       "  [[[2.0, 92.0], [146.0, 92.0], [146.0, 106.0], [2.0, 106.0]],\n",
       "   ('4 - Emprunts et ressources speciales', 0.9804349541664124)],\n",
       "  [[[294.0, 91.0], [312.0, 91.0], [312.0, 109.0], [294.0, 109.0]],\n",
       "   ('4.9', 0.9821820259094238)],\n",
       "  [[[352.0, 91.0], [378.0, 91.0], [378.0, 107.0], [352.0, 107.0]],\n",
       "   ('2 595', 0.9830156564712524)],\n",
       "  [[[431.0, 93.0], [455.0, 93.0], [455.0, 106.0], [431.0, 106.0]],\n",
       "   ('3 613', 0.9977636337280273)],\n",
       "  [[[2.0, 111.0], [71.0, 111.0], [71.0, 122.0], [2.0, 122.0]],\n",
       "   ('5 - Autres passifs', 0.9954730272293091)],\n",
       "  [[[290.0, 106.0], [312.0, 109.0], [310.0, 126.0], [288.0, 122.0]],\n",
       "   ('4.10', 0.9963530898094177)],\n",
       "  [[[354.0, 111.0], [377.0, 111.0], [377.0, 123.0], [354.0, 123.0]],\n",
       "   ('8 610', 0.9989112615585327)],\n",
       "  [[[427.0, 110.0], [456.0, 110.0], [456.0, 125.0], [427.0, 125.0]],\n",
       "   ('11 914', 0.9835768342018127)],\n",
       "  [[[345.0, 126.0], [378.0, 129.0], [377.0, 143.0], [344.0, 140.0]],\n",
       "   ('146 170', 0.9561330676078796)],\n",
       "  [[[115.0, 136.0], [174.0, 136.0], [174.0, 147.0], [115.0, 147.0]],\n",
       "   ('TOTAL PASSIF', 0.9925675392150879)],\n",
       "  [[[422.0, 128.0], [457.0, 128.0], [457.0, 143.0], [422.0, 143.0]],\n",
       "   ('155 577', 0.9966875910758972)],\n",
       "  [[[19.0, 154.0], [105.0, 154.0], [105.0, 168.0], [19.0, 168.0]],\n",
       "   ('CAPITAUX PROPRES', 0.998300313949585)],\n",
       "  [[[2.0, 173.0], [43.0, 173.0], [43.0, 184.0], [2.0, 184.0]],\n",
       "   ('1 - Capital', 0.9966543316841125)],\n",
       "  [[[349.0, 172.0], [378.0, 175.0], [377.0, 191.0], [347.0, 188.0]],\n",
       "   ('40.000', 0.8212328553199768)],\n",
       "  [[[427.0, 172.0], [457.0, 175.0], [455.0, 191.0], [426.0, 188.0]],\n",
       "   ('18.000', 0.930640697479248)],\n",
       "  [[[1.0, 189.0], [51.0, 189.0], [51.0, 204.0], [1.0, 204.0]],\n",
       "   ('2 - Reserves', 0.9660890698432922)],\n",
       "  [[[358.0, 191.0], [379.0, 191.0], [379.0, 208.0], [358.0, 208.0]],\n",
       "   ('277', 0.9991359710693359)],\n",
       "  [[[436.0, 191.0], [456.0, 191.0], [456.0, 208.0], [436.0, 208.0]],\n",
       "   ('277', 0.9989568591117859)],\n",
       "  [[[1.0, 216.0], [78.0, 216.0], [78.0, 230.0], [1.0, 230.0]],\n",
       "   ('3 - Actions propres', 0.9822414517402649)],\n",
       "  [[[367.0, 218.0], [379.0, 218.0], [379.0, 234.0], [367.0, 234.0]],\n",
       "   ('0', 0.9470760822296143)],\n",
       "  [[[445.0, 218.0], [457.0, 218.0], [457.0, 234.0], [445.0, 234.0]],\n",
       "   ('0', 0.9470760822296143)],\n",
       "  [[[1.0, 239.0], [108.0, 239.0], [108.0, 252.0], [1.0, 252.0]],\n",
       "   ('4 - Autres capitaux propres', 0.985622763633728)],\n",
       "  [[[367.0, 241.0], [379.0, 241.0], [379.0, 257.0], [367.0, 257.0]],\n",
       "   ('0', 0.9470760822296143)],\n",
       "  [[[2.0, 259.0], [86.0, 259.0], [86.0, 272.0], [2.0, 272.0]],\n",
       "   ('5 - Resultats reportes', 0.9457952976226807)],\n",
       "  [[[349.0, 259.0], [378.0, 262.0], [377.0, 278.0], [347.0, 275.0]],\n",
       "   ('(5 772)', 0.9578251242637634)],\n",
       "  [[[425.0, 262.0], [455.0, 262.0], [455.0, 277.0], [425.0, 277.0]],\n",
       "   ('(3 274)', 0.9985886216163635)],\n",
       "  [[[1.0, 276.0], [98.0, 276.0], [98.0, 290.0], [1.0, 290.0]],\n",
       "   (\"6 - Resultat de I'exercice\", 0.9703696370124817)],\n",
       "  [[[343.0, 277.0], [378.0, 280.0], [377.0, 295.0], [342.0, 292.0]],\n",
       "   ('(19 670)', 0.9964416027069092)],\n",
       "  [[[425.0, 279.0], [456.0, 279.0], [456.0, 295.0], [425.0, 295.0]],\n",
       "   ('(2 498)', 0.9768916368484497)],\n",
       "  [[[5.0, 305.0], [119.0, 305.0], [119.0, 319.0], [5.0, 319.0]],\n",
       "   ('TOTAL CAPITAUX PROPRES', 0.9985042214393616)],\n",
       "  [[[282.0, 305.0], [300.0, 305.0], [300.0, 319.0], [282.0, 319.0]],\n",
       "   ('4.11', 0.9867630004882812)],\n",
       "  [[[348.0, 297.0], [379.0, 299.0], [378.0, 315.0], [346.0, 312.0]],\n",
       "   ('14 835', 0.9921324253082275)],\n",
       "  [[[427.0, 296.0], [458.0, 299.0], [456.0, 315.0], [426.0, 312.0]],\n",
       "   ('12 505', 0.9788274765014648)],\n",
       "  [[[2.0, 319.0], [160.0, 319.0], [160.0, 330.0], [2.0, 330.0]],\n",
       "   ('TOTAL PASSIF ET CAPITAUX PROPRES', 0.94297194480896)],\n",
       "  [[[345.0, 320.0], [377.0, 320.0], [377.0, 330.0], [345.0, 330.0]],\n",
       "   ('161 005', 0.9486441016197205)],\n",
       "  [[[423.0, 320.0], [456.0, 320.0], [456.0, 330.0], [423.0, 330.0]],\n",
       "   ('168 082', 0.9407562017440796)]]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['decoder.output_projection.weight', 'encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "# load image from the IAM dataset\n",
    "img = Image.open(img_path)\n",
    "\n",
    "image = img.convert(\"RGB\")\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRConfig, TrOCRForCausalLM\n",
    "\n",
    "# Initializing a TrOCR-base style configuration\n",
    "configuration = TrOCRConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the TrOCR-base style configuration\n",
    "model = TrOCRForCausalLM(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TrOCRConfig,\n",
    "    TrOCRProcessor,\n",
    "    TrOCRForCausalLM,\n",
    "    ViTConfig,\n",
    "    ViTModel,\n",
    "    VisionEncoderDecoderModel,\n",
    ")\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "# TrOCR is a decoder model and should be used within a VisionEncoderDecoderModel\n",
    "# init vision2text model with random weights\n",
    "encoder = ViTModel(ViTConfig())\n",
    "decoder = TrOCRForCausalLM(TrOCRConfig())\n",
    "model = VisionEncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "# If you want to start from the pretrained model, load the checkpoint with `VisionEncoderDecoderModel`\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "# load image from the IAM dataset\n",
    "uimg = Image.open(img_path)\n",
    "\n",
    "image = img.convert(\"RGB\")\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "text = \"industry, ' Mr. Brown commented icily. ' Let us have a\"\n",
    "\n",
    "# training\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "labels = processor.tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "outputs = model(pixel_values, labels=labels)\n",
    "loss = outputs.loss\n",
    "round(loss.item(), 2)\n",
    "\n",
    "# inference\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
